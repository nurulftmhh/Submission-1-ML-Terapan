# -*- coding: utf-8 -*-
"""Proyek Pertama : Predictive Analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RkInriG_Xzsqy0Abt25LokV2RDGmeyhu

**Nama       : Nurul Fatimah**

**Submission : Predictive Analytics**

####Data Loading

Mengambil data yang sudah tersimpan dalam Google Drive, membacanya ke dalam DataFrame menggunakan Pandas, dan menampilkan lima baris pertama data tersebut. Untuk melakukan proses tersebut perlu mengimport library maupun modul yang dibutuhkan.
"""

# Mengimport library pandas
import pandas as pd

# Mengimport modul drive untuk akses ke google drive
from google.colab import drive

# Mengakses Google Drive
drive.mount('/content/drive')

# Membuat file_path yang akan diakses
file_path = '/content/drive/My Drive/dataset/ADS/Ecommerce_Customers.csv'

# Membaca file_path
df = pd.read_csv(file_path)

# Menampilkan 5 data teratas (head)
df

"""####Exploratory Data Analysis

Dataset (Ecommerce_Customers.csv) berisi variabel-variabel berikut:

* Email : Alamat email pelanggan.
* Address : Alamat rumah pelanggan.
* Avatar : Avatar yang dipilih oleh pelanggan di situs online toko.
* Avg. Session Length : Rata-rata waktu yang dihabiskan ketika mengikuti sesi saran gaya di dalam toko.
* Time on App : Rata-rata waktu yang dihabiskan di Aplikasi dalam hitungan menit.
* Time on Website : Rata-rata waktu yang dihabiskan di Situs Web dalam hitungan menit.
* Length of Membership : Berapa tahun pelanggan telah menjadi anggota.
* Yearly amount spent : Uang yang digunakan oleh pelanggan untuk membeli produk per tahunnya. Ini merupakan fitur target.

Kemudian, mengecek informasi pada dataset dengan fungsi info().
"""

# Melihat informasi data
df.info()

"""Dari output terlihat bahwa:

* Terdapat 3 kolom dengan tipe object, yaitu: Email, Address, dan Avatar. Kolom ini merupakan categorical features (fitur non-numerik).
* Terdapat 5 kolom numerik dengan tipe data float64 yaitu: Avg. Session Length, Time on App, Time on Website, Length of Membership, dan Yearly Amount Spent.

Setelah itu, perlu mengecek deskripsi statistik data dengan fitur describe(), yang mana outputnya akan menampilkan statistik (count, unique, top, freq, mean, std, min, 25%, 50%, 75%, max) dari setiap kolom.
"""

# Melihat statistik data
print("Statistik deskriptif dari data : ")
df.describe(include='all')

"""Selanjutnya, melakukan pengecekan apakah terdapat data kosong dengan menggunakan fungsi isnull()"""

# Melihat apakah ada data kosong
df.isnull().sum()

"""Hasilnya menunjukkan bahwa tidak terdapat data kosong dari setiap kolomnya.

Kemudian melakukan pengecekkan apakah terdapat data duplikat atau tidak menggunakan perintah duplicated()
"""

# Melihat apakah ada data yang duplikat
df.duplicated().sum()

"""Outputnya menunjukkan bahwa tidak terdapat data duplikat

Selanjutnya, menentukan kolom yang akan dipilih untuk analisis. Disini saya hanya menggunakan kolom numerik, dikarenakan kolom Email dan Address tidak memiliki pengaruh terhadap banyaknya uang yang akan pelanggan habiskan.
"""

# Kolom yang dipilih untuk analisis
selected_X = ["Avg. Session Length", "Time on App", "Time on Website", "Length of Membership", "Yearly Amount Spent"]

new_df = df[selected_X]
new_df

"""Outputnya menampilkan 5 kolom (Avg. Session Length, Time on App, Time on Website, Length of Membership, dan Yearly Amount Spent) dengan jumlah datanya yaitu 500 data.

Melihat korelasi antar variabel yang divisualisasikan dalam bentuk heatmap.
"""

#Melihat korelasi antar variabel
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=[18,8])
sns.heatmap(new_df[["Avg. Session Length", "Time on App", "Time on Website", "Length of Membership", "Yearly Amount Spent"]].corr(method='pearson'), annot = True, cmap = 'coolwarm')

"""Korelasi merupakan ukuran statistik yang menunjukkan sejauh mana dua variabel berhubungan satu sama lain. Dari visualisasi korelasi tersebut, fitur yang paling berpengaruh dengan Yearly Amount Spent yaitu **Length of Membership** .

Koefisien Korelasi memiliki rentang -1 sampai 1.
- r=1: Korelasi positif sempurna. Kedua variabel bergerak dalam arah yang sama secara sempurna.
- r=âˆ’1: Korelasi negatif sempurna. Kedua variabel bergerak dalam arah yang berlawanan secara sempurna.
- r=0: Tidak ada korelasi linier. Tidak ada hubungan linier antara dua variabel.

Jenis-Jenis Korelasi
- Korelasi Positif: Ketika satu variabel meningkat, variabel lainnya juga cenderung meningkat.
- Korelasi Negatif:Ketika satu variabel meningkat, variabel lainnya cenderung menurun.
- Korelasi Nol: Tidak ada hubungan linier antara kedua variabel. Perubahan dalam satu variabel tidak mempengaruhi variabel lainnya.

Melakukan visualisasi data numerik dalam bentuk histogram untuk melihat persebaran datanya. Dalam proses ini perlu mengimport library matplotlib dan seaborn terlebih dahulu.
"""

#Visualisasi data dalam bentuk histogram untuk melihat distribusi variabel
num_features = ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership', 'Yearly Amount Spent']
new_df[num_features].hist(bins=30, figsize=(20, 15))
plt.show()

"""Selain di visualisasikan dalam bentuk histogram, disini saya mencoba mem visualisasikan dalam bentuk boxplot agar bisa melihat ada tidaknya outlier."""

#Melihat ada tidaknya outliers
plt.figure(figsize=(15, 10))
for i, feature in enumerate(num_features):
    plt.subplot(2, 3, i+1)
    sns.boxplot(new_df[feature], orient='h', color='red')
    plt.title(f'Boxplot {feature}')
    plt.ylabel(feature)
plt.tight_layout()
plt.show()

"""Hasilnya menampilkan bahwa terdapat beberapa outlier di kelima fitur numeriknya

####Data Preparation

Melakukan standarisasi data dengan menggunakan fungsi StandardScaler(). Standarisasi adalah proses mengubah skala fitur atau variabel data sehingga distribusinya memiliki rata-rata 0 dan standar deviasi 1. Hal ini dilakukan agar semua fitur pada data memiliki skala yang sama serta membantu meningkatkan kinerja model dan mempercepat proses machine learning.
"""

#Kontruksi data menggunakan StandarScaler
from sklearn.preprocessing import StandardScaler

# Normalisasi data
scaler = StandardScaler()
new_df[num_features] = scaler.fit_transform(new_df[num_features])
new_df

"""Karena tadi ditemukan outlier, disini saya mencoba melakukan penghapusan outlier dengan menggunakan mettode IQR (Interquartile Range).
* Q1 dan Q3 adalah kuartil pertama dan ketiga dari setiap fitur numerik dalam new_df. Kuartil pertama (Q1) adalah nilai di bawah mana 25% dari data berada, sedangkan kuartil ketiga (Q3) adalah nilai di bawah mana 75% dari data berada.
* IQR adalah jarak antara kuartil ketiga dan kuartil pertama. IQR digunakan untuk mengukur rentang tengah dari data dan sering digunakan untuk mendeteksi outlier.
* cek_outlier adalah DataFrame boolean yang menunjukkan apakah setiap nilai dalam new_df adalah outlier berdasarkan aturan umum bahwa nilai dianggap outlier jika berada lebih dari 1.5 kali IQR di bawah Q1 atau di atas Q3.
* mask adalah Series boolean yang menunjukkan apakah setiap baris dalam new_df tidak mengandung outlier. Fungsi any(axis=1) memeriksa apakah ada outlier dalam satu baris (untuk semua fitur numerik), dan ~ adalah operator NOT yang membalikkan nilai boolean.
* df_data adalah DataFrame baru yang berisi hanya baris-baris dari new_df yang tidak mengandung outlier berdasarkan mask boolean yang dibuat sebelumnya.
"""

# Hitung Q1 dan Q3
Q1 = new_df[num_features].quantile(0.25)
Q3 = new_df[num_features].quantile(0.75)

# Hitung IQR
IQR = Q3 - Q1
cek_outlier = (new_df[num_features] < (Q1 - 1.5 * IQR)) | (new_df[num_features] > (Q3 + 1.5 * IQR))

# Membuat mask boolean untuk data yang tidak mengandung outlier
mask = ~cek_outlier.any(axis=1)

# Filter data untuk menghapus outlier
df_data = new_df[mask]
df_data

"""Data yang tersisa sejumlah 476. Visualisasikan kembali data sesudah dilakukan penghapusan outlier."""

#Setelah penghapusan outlier
plt.figure(figsize=(15, 10))
for i, feature in enumerate(num_features):
    plt.subplot(2, 3, i+1)

    sns.boxplot(df_data[feature], orient='h', color='red')
    plt.title(f'Boxplot {feature}')
    plt.ylabel(feature)
plt.tight_layout()
plt.show()

"""####Modelling

Setelah data di preprocessing, langkah selanjutnya yaitu modelling. Disini saya mencoba menggunakan model regresi linear dan juga random forest

* Model Regresi Linear
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

features = ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']
target = 'Yearly Amount Spent'
# Membagi data
X = df_data[features]
y = df_data[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Melatih model regresi linier
model_reg = LinearRegression(fit_intercept=True, copy_X=True, n_jobs=None)
model_reg.fit(X_train, y_train)

# Melakukan prediksi
y_pred = model_reg.predict(X_test)

"""1. Import dan Pembagian Dataset:

   * from sklearn.model_selection import train_test_split: Mengimpor fungsi untuk membagi dataset menjadi data pelatihan dan pengujian.

   * from sklearn.linear_model import LinearRegression: Mengimpor model regresi linier dari scikit-learn.

   * features = ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']: Mendefinisikan variabel input atau fitur yang digunakan untuk memprediksi target. Fitur-fitur ini merupakan kolom-kolom dalam dataset.

   * target = 'Yearly Amount Spent': Mendefinisikan variabel target yang ingin diprediksi, dalam hal ini adalah "Yearly Amount Spent".

2. Membagi Dataset:

   * X = df_data[features]: Memisahkan fitur-fitur dari dataset ke dalam variabel X.

   * y = df_data[target]: Memisahkan target (label) dari dataset ke dalam variabel y.

   * X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42): Membagi dataset menjadi dua bagian, yaitu data pelatihan (X_train, y_train) dan data pengujian (X_test, y_test). Parameter test_size=0.3 menunjukkan bahwa 30% data digunakan untuk pengujian, dan random_state=42 digunakan untuk memastikan bahwa pembagian data ini dapat direproduksi.

3. Melatih Model:

   * model_reg = LinearRegression(fit_intercept=True, copy_X=True, n_jobs=None): membuat model regresi linier dengan parameter tertentu
   * model.fit(X_train, y_train): Melatih model regresi linier menggunakan data pelatihan (X_train, y_train).

4. Prediksi:

   * y_pred = model.predict(X_test): Menggunakan model yang sudah dilatih untuk memprediksi nilai target pada data pengujian (X_test). Hasil prediksi disimpan dalam variabel y_pred.

Kemudian, setelah membangun model perlu dilakukan evaluasi model dengan tujuan untuk menilai kinerja model yang telah dibuat dalam memprediksi data baru.

* Evaluasi Model Regresi Linear
"""

# Evaluasi model
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error: {mae}')
print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

"""Hasil evaluasi model regresi linear yang didapat dari ketiga metrik tersebut yaitu:
* Mean Absolute Error (MAE): 0.1033. Semakin kecil nilai MAE, semakin baik model dalam memprediksi.
* Mean Squared Error (MSE): 0.0174. Semakin kecil nilai MSE, semakin baik performa model.
* R-squared (RÂ²): 0.9798. Nilai RÂ² berkisar dari 0 hingga 1, di mana nilai yang lebih mendekati 1 menunjukkan bahwa model mampu menjelaskan sebagian besar variansi data target, berarti sekitar 97.98% variasi dari target (Yearly Amount Spent) dapat dijelaskan oleh model regresi linier ini.  

Secara keseluruhan, model ini memiliki performa yang baik, dengan error yang rendah (MAE dan MSE) dan RÂ² yang tinggi, menunjukkan bahwa model ini cukup akurat dalam memprediksi variabel target.

Selanjutnya, membuat visualisasi dalam bentuk scatter plot yang digunakan untuk membandingkan hasil prediksi model regresi linear dengan nilai sebenarnya dari data pengujian
"""

# Membuat scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, y_test, color='blue', alpha=0.5, edgecolors='k')
plt.xlabel('Prediksi (y_pred)')
plt.ylabel('Hasil Sebenarnya (y_test)')
plt.title('Scatter Plot Prediksi vs Hasil Sebenarnya (Linear Regression)')

plt.plot([y_pred.min(), y_pred.max()], [y_test.min(), y_test.max()], 'r--', lw=2)

plt.grid(True)
plt.show()

"""Dari scatter plot yang ditampilkan, dapat ditarik kesimpulan bahwa model regresi linear yang digunakan memiliki performa prediksi yang sangat baik, karena titik-titik pada plot cenderung terdistribusi secara merata di sepanjang garis referensi. Ada sedikit penyimpangan (titik-titik yang tidak persis di garis merah), tetapi secara keseluruhan, hasilnya menunjukkan bahwa model cukup akurat dalam memprediksi nilai target.

* Model Random Forest
"""

from sklearn.ensemble import RandomForestRegressor

# Melatih model Random Forest
model_rf = RandomForestRegressor(random_state=42)
model_rf.fit(X_train, y_train)

# Melakukan prediksi
y_pred = model_rf.predict(X_test)

"""1. Impor RandomForestRegressor:

   * from sklearn.ensemble import RandomForestRegressor: Mengimpor model Random Forest Regressor dari library scikit-learn.
2. Inisialisasi Model:

  * model_rf = RandomForestRegressor(random_state=42): Membuat objek model Random Forest Regressor dengan parameter random_state diatur ke 42 untuk memastikan hasil yang konsisten setiap kali model dijalankan.
3. Melatih Model:

  * model_rf.fit(X_train, y_train): Melatih model menggunakan data pelatihan (X_train untuk fitur dan y_train untuk target). Model akan mempelajari hubungan antara fitur dan target.
4. Melakukan Prediksi:

  * y_pred = model_rf.predict(X_test): Menggunakan model yang telah dilatih untuk memprediksi nilai target (y_pred) berdasarkan data uji (X_test).

* Evaluasi Model Random Forest
"""

# Evaluasi model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error: {mae}')
print(f"Mean Squared Error (MSE): {mse}")
print(f"R-squared (R2): {r2}")

"""Hasil evaluasi model random forest yang didapat dari kedua metrik tersebut yaitu:
* Mean Absolute Error (MAE): 0.198. Semakin kecil nilai MAE, semakin baik model dalam memprediksi.
* Mean Squared Error (MSE): 0.0656. Semakin kecil nilai MSE, semakin baik performa model.
* R-squared (RÂ²): 0.924. Nilai RÂ² berkisar dari 0 hingga 1, di mana nilai yang lebih mendekati 1 menunjukkan bahwa model mampu menjelaskan sebagian besar variansi data target, berarti sekitar 92.4% variasi dari target (Yearly Amount Spent) dapat dijelaskan oleh model random forest ini.  

Secara keseluruhan, model Random Forest yang digunakan memiliki performa yang kuat, dengan kesalahan prediksi yang rendah dan kemampuan yang tinggi dalam menjelaskan variasi data.
"""

# Membuat scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, y_test, color='blue', alpha=0.5, edgecolors='k')
plt.xlabel('Prediksi (y_pred)')
plt.ylabel('Hasil Sebenarnya (y_test)')
plt.title('Scatter Plot Prediksi vs Hasil Sebenarnya (Random Forest)')

plt.plot([y_pred.min(), y_pred.max()], [y_test.min(), y_test.max()], 'r--', lw=2)

plt.grid(True)
plt.show()

"""Dari scatter plot yang ditunjukkan, sebagian besar titik berada di sekitar garis merah, menunjukkan bahwa model Random Forest melakukan prediksi yang cukup baik. Beberapa titik berada agak jauh dari garis merah, yang menunjukkan adanya kesalahan prediksi oleh model. Namun, secara keseluruhan, titik-titik tersebut tidak terlalu menyebar jauh dari garis, yang menunjukkan bahwa kesalahan prediksi model relatif kecil. Mengingat banyaknya titik yang dekat dengan garis merah, ini mengindikasikan bahwa model Random Forest memiliki kemampuan prediksi yang cukup baik pada data uji ini.

####Hasil Evalusi Kedua Model

Kesimpulan Utama:
* Dalam kasus ini, model Regresi Linear tampaknya memberikan hasil yang lebih baik dibandingkan Random Forest, baik dari segi kesalahan prediksi (MSE) dan (MAE) yang lebih rendah maupun kemampuan menjelaskan variasi dalam data (RÂ²) yang lebih tinggi.
* Oleh karena itu, model Regresi Linear lebih cocok digunakan untuk data ini daripada model Random Forest, karena memberikan prediksi yang lebih akurat dan lebih baik dalam menjelaskan hubungan antara variabel prediktor dan target.

####Koefisien Regresi

Kemudian, melihat koefisien regresi dari model regresi linier yang sudah dilatih. Koefisien regresi menunjukkan seberapa besar pengaruh setiap fitur terhadap target yang diprediksi.
"""

# Melihat koefisien regresi
coefficients = pd.DataFrame(model_reg.coef_, features, columns=['Coefficient'])
print(coefficients)

"""Semua koefisien positif menunjukkan bahwa setiap fitur berhubungan positif dengan Yearly Amount Spent. Artinya, jika fitur meningkat, pengeluaran tahunan (Yearly Amount Spent) juga diperkirakan meningkat.
* Avg. Session Length (0.323443): setiap peningkatan satu satuan pada rata-rata panjang sesi (Avg. Session Length) akan meningkatkan prediksi pengeluaran tahunan (Yearly Amount Spent) sebesar 0.323443 unit
* Time on App (0.488632): setiap peningkatan satu satuan waktu yang dihabiskan di aplikasi (Time on App) akan meningkatkan pengeluaran tahunan (Yearly Amount Spent) sebesar 0.488632 unit
* Time on Website (0.004919): berarti bahwa waktu yang dihabiskan di website (Time on Website) memiliki pengaruh yang sangat kecil terhadap pengeluaran tahunan (Yearly Amount Spent)
* Length of Membership (0.767740): setiap peningkatan satu satuan pada lamanya keanggotaan (Length of Membership) akan meningkatkan pengeluaran tahunan (Yearly Amount Spent) sebesar 0.767740 unit.

Dapat disimpulkan, bahwa:
* Fitur Length of Membership memiliki pengaruh paling besar terhadap pengeluaran tahunan, diikuti oleh Time on App dan Avg. Session Length.
* Time on Website memiliki pengaruh yang sangat kecil dan hampir tidak signifikan dalam mempengaruhi pengeluaran tahunan.

####Kesimpulan

Dari hasil tersebut, dapat dilihat bahwa bahwa untuk meningkatkan pengeluaran tahunan pengguna (Yearly Amount Spent), perusahaan mungkin harus lebih fokus pada peningkatan durasi keanggotaan (Length of Membership) dan meningkatkan keterlibatan pengguna melalui aplikasi, daripada melalui website.
"""